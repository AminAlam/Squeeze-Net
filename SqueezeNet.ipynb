{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SqueezeNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWVkZrxwzMHe",
        "outputId": "f8d460b7-953a-4dd4-bf8d-a1a6e21205c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, BatchNormalization, Dropout, AveragePooling2D\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing CIFAR10 dataset and separating them"
      ],
      "metadata": {
        "id": "U6Xfqmp09G0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "\n",
        "file_name = \"/content/drive/My Drive/Courses/DeepLearning/HW02/Q03/datas/data_batch_{0}\".format(1)\n",
        "train = unpickle(file_name)\n",
        "for i in range(2,6):\n",
        "    file_name = \"/content/drive/My Drive/Courses/DeepLearning/HW02/Q03/datas/data_batch_{0}\".format(i)\n",
        "    temp = unpickle(file_name)\n",
        "    train[b'data'] = np.concatenate((train[b'data'], temp[b'data']))\n",
        "    train[b'labels'] = np.concatenate((train[b'labels'], temp[b'labels']))   \n",
        "\n",
        "indices = tf.range(start=0, limit=tf.shape(train[b'labels'])[0], dtype=tf.int32)\n",
        "shuffled_indices = tf.random.shuffle(indices)\n",
        "\n",
        "train[b'data'] = tf.gather(train[b'data'], shuffled_indices)\n",
        "train[b'labels'] = tf.gather(train[b'labels'], shuffled_indices)\n",
        "\n",
        "validation = {}\n",
        "num_train = 40000\n",
        "validation[b'data'] = train[b'data'][num_train:]\n",
        "validation[b'labels'] = train[b'labels'][num_train:]\n",
        "\n",
        "train[b'data'] = train[b'data'][0:num_train]\n",
        "train[b'labels'] = train[b'labels'][0:num_train]\n",
        "\n",
        "file_name = \"/content/drive/My Drive/Courses/DeepLearning/HW02/Q03/datas/test_batch\"\n",
        "test = unpickle(file_name)\n",
        "\n",
        "\n",
        "indices = tf.range(start=0, limit=tf.shape(test[b'labels'])[0], dtype=tf.int32)\n",
        "shuffled_indices = tf.random.shuffle(indices)\n",
        "\n",
        "test[b'data'] = tf.gather(test[b'data'], shuffled_indices)\n",
        "test[b'labels'] = tf.gather(test[b'labels'], shuffled_indices)\n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "feature_vector_length = 32*32*3\n",
        "input_shape = (feature_vector_length,)\n",
        "img_size_1D = int(np.sqrt(feature_vector_length/3))\n",
        "\n",
        "\n",
        "X_train = train[b'data']/255\n",
        "Y_train = tf.keras.utils.to_categorical(train[b'labels'], num_classes)\n",
        "\n",
        "X_validation = validation[b'data']/255\n",
        "Y_validation = tf.keras.utils.to_categorical(validation[b'labels'], num_classes)\n",
        "\n",
        "X_test = test[b'data']/255\n",
        "Y_test = tf.keras.utils.to_categorical(test[b'labels'], num_classes)\n",
        "\n",
        "\n",
        "X_train_3D = np.reshape(X_train,(40000,img_size_1D, img_size_1D, 3))\n",
        "X_validation_3D = np.reshape(X_validation,(10000, img_size_1D, img_size_1D, 3))\n",
        "X_test_3D = np.reshape(X_test,(10000,img_size_1D, img_size_1D, 3))"
      ],
      "metadata": {
        "id": "NdzdWMmX9Mvv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_3D.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmuOzR5gA3a3",
        "outputId": "7858bbe7-02da-4e20-b256-4ca383304bce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing the Model"
      ],
      "metadata": {
        "id": "O3scarABze4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs_number = 40\n",
        "learning_rate = 1e-3\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (1,1), kernel_initializer='glorot_uniform', padding='same', name='conv1', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "\n",
        "model.add(Conv2D(16, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire2_squeeze'))\n",
        "model.add(Conv2D(64, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire2_conv1'))\n",
        "model.add(Conv2D(64, (3,3), kernel_initializer='glorot_uniform', padding='same', name='fire2_conv2'))\n",
        "\n",
        "model.add(Conv2D(16, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire3_squeeze'))\n",
        "model.add(Conv2D(64, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire3_conv1'))\n",
        "model.add(Conv2D(64, (3,3), kernel_initializer='glorot_uniform', padding='same', name='fire3_conv2'))\n",
        "\n",
        "model.add(Conv2D(32, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire4_squeeze'))\n",
        "model.add(Conv2D(128, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire4_conv1'))\n",
        "model.add(Conv2D(128, (3,3), kernel_initializer='glorot_uniform', padding='same', name='fire4_conv2'))\n",
        "\n",
        "model.add(Conv2D(32, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire5_squeeze'))\n",
        "model.add(Conv2D(128, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire5_conv1'))\n",
        "model.add(Conv2D(128, (3,3), kernel_initializer='glorot_uniform', padding='same', name='fire5_conv2'))\n",
        "\n",
        "model.add(Conv2D(48, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire6_squeeze'))\n",
        "model.add(Conv2D(192, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire6_conv1'))\n",
        "model.add(Conv2D(192, (3,3), kernel_initializer='glorot_uniform', padding='same', name='fire6_conv2'))\n",
        "\n",
        "model.add(Conv2D(48, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire7_squeeze'))\n",
        "model.add(Conv2D(192, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire7_conv1'))\n",
        "model.add(Conv2D(192, (3,3), kernel_initializer='glorot_uniform', padding='same', name='fire7_conv2'))\n",
        "\n",
        "model.add(Conv2D(64, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire8_squeeze'))\n",
        "model.add(Conv2D(256, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire8_conv1'))\n",
        "model.add(Conv2D(256, (3,3), kernel_initializer='glorot_uniform', padding='same', name='fire8_conv2'))\n",
        "model.add(MaxPooling2D((3, 3)))\n",
        "\n",
        "model.add(Conv2D(64, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire9_squeeze'))\n",
        "model.add(Conv2D(256, (1,1), kernel_initializer='glorot_uniform', padding='same', name='fire9_conv1'))\n",
        "model.add(Conv2D(256, (3,3), kernel_initializer='glorot_uniform', padding='same', name='fire9_conv2'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(1000, (1,1), kernel_initializer='glorot_uniform', padding='valid', name='conv10'))\n",
        "model.add(AveragePooling2D((3, 3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.fit(X_train_3D, Y_train, epochs=epochs_number, batch_size=batch_size, validation_data=(X_validation_3D, Y_validation))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFMZIngKzjFL",
        "outputId": "3494012f-b40e-4e47-a6d9-a0b32c437c24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "625/625 [==============================] - 54s 68ms/step - loss: 2.0541 - accuracy: 0.2518 - val_loss: 1.7878 - val_accuracy: 0.3182\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 1.7722 - accuracy: 0.3547 - val_loss: 1.6528 - val_accuracy: 0.4088\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 1.6624 - accuracy: 0.4031 - val_loss: 1.6654 - val_accuracy: 0.4075\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 1.5979 - accuracy: 0.4298 - val_loss: 1.6098 - val_accuracy: 0.4253\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 1.5558 - accuracy: 0.4467 - val_loss: 1.4693 - val_accuracy: 0.4748\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.5016 - accuracy: 0.4678 - val_loss: 1.6113 - val_accuracy: 0.4506\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.4718 - accuracy: 0.4793 - val_loss: 1.4228 - val_accuracy: 0.4939\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.4529 - accuracy: 0.4855 - val_loss: 1.4614 - val_accuracy: 0.4939\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.4267 - accuracy: 0.4963 - val_loss: 1.4234 - val_accuracy: 0.4913\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.3884 - accuracy: 0.5084 - val_loss: 1.3471 - val_accuracy: 0.5262\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.3641 - accuracy: 0.5181 - val_loss: 1.3609 - val_accuracy: 0.5213\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 1.3399 - accuracy: 0.5280 - val_loss: 1.3432 - val_accuracy: 0.5199\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 1.3165 - accuracy: 0.5344 - val_loss: 1.3409 - val_accuracy: 0.5326\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 1.3029 - accuracy: 0.5393 - val_loss: 1.3158 - val_accuracy: 0.5357\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 1.2690 - accuracy: 0.5525 - val_loss: 1.4008 - val_accuracy: 0.5059\n",
            "Epoch 16/40\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 1.2533 - accuracy: 0.5597 - val_loss: 1.3177 - val_accuracy: 0.5388\n",
            "Epoch 17/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.2349 - accuracy: 0.5651 - val_loss: 1.3655 - val_accuracy: 0.5304\n",
            "Epoch 18/40\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 1.2151 - accuracy: 0.5715 - val_loss: 1.3027 - val_accuracy: 0.5403\n",
            "Epoch 19/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 1.1956 - accuracy: 0.5809 - val_loss: 1.2923 - val_accuracy: 0.5477\n",
            "Epoch 20/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.1818 - accuracy: 0.5822 - val_loss: 1.2572 - val_accuracy: 0.5674\n",
            "Epoch 21/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.1580 - accuracy: 0.5908 - val_loss: 1.3022 - val_accuracy: 0.5522\n",
            "Epoch 22/40\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 1.1469 - accuracy: 0.5956 - val_loss: 1.3371 - val_accuracy: 0.5323\n",
            "Epoch 23/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 1.1348 - accuracy: 0.6010 - val_loss: 1.2752 - val_accuracy: 0.5617\n",
            "Epoch 24/40\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 1.1076 - accuracy: 0.6089 - val_loss: 1.2336 - val_accuracy: 0.5717\n",
            "Epoch 25/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.1041 - accuracy: 0.6081 - val_loss: 1.3345 - val_accuracy: 0.5407\n",
            "Epoch 26/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 1.0818 - accuracy: 0.6169 - val_loss: 1.2712 - val_accuracy: 0.5688\n",
            "Epoch 27/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.0800 - accuracy: 0.6204 - val_loss: 1.2449 - val_accuracy: 0.5667\n",
            "Epoch 28/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.0483 - accuracy: 0.6295 - val_loss: 1.2941 - val_accuracy: 0.5621\n",
            "Epoch 29/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.0433 - accuracy: 0.6332 - val_loss: 1.2716 - val_accuracy: 0.5705\n",
            "Epoch 30/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.0239 - accuracy: 0.6382 - val_loss: 1.2750 - val_accuracy: 0.5564\n",
            "Epoch 31/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 1.0146 - accuracy: 0.6412 - val_loss: 1.3082 - val_accuracy: 0.5469\n",
            "Epoch 32/40\n",
            "625/625 [==============================] - 40s 63ms/step - loss: 0.9958 - accuracy: 0.6499 - val_loss: 1.3279 - val_accuracy: 0.5653\n",
            "Epoch 33/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 0.9874 - accuracy: 0.6510 - val_loss: 1.3118 - val_accuracy: 0.5662\n",
            "Epoch 34/40\n",
            "625/625 [==============================] - 40s 64ms/step - loss: 0.9732 - accuracy: 0.6563 - val_loss: 1.2650 - val_accuracy: 0.5754\n",
            "Epoch 35/40\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.9642 - accuracy: 0.6574 - val_loss: 1.2751 - val_accuracy: 0.5688\n",
            "Epoch 36/40\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.9541 - accuracy: 0.6627 - val_loss: 1.2587 - val_accuracy: 0.5848\n",
            "Epoch 37/40\n",
            "625/625 [==============================] - 42s 67ms/step - loss: 0.9421 - accuracy: 0.6673 - val_loss: 1.3069 - val_accuracy: 0.5663\n",
            "Epoch 38/40\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.9278 - accuracy: 0.6715 - val_loss: 1.3053 - val_accuracy: 0.5719\n",
            "Epoch 39/40\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.9277 - accuracy: 0.6716 - val_loss: 1.2461 - val_accuracy: 0.5803\n",
            "Epoch 40/40\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.9057 - accuracy: 0.6779 - val_loss: 1.3060 - val_accuracy: 0.5748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48f04f2d10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_number = 120\n",
        "model.fit(X_train_3D, Y_train, epochs=epochs_number, batch_size=batch_size, validation_data=(X_validation_3D, Y_validation), initial_epoch=40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2y2mI66IdK3",
        "outputId": "bb5d731d-f621-4519-bc9a-06bd77734d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.8983 - accuracy: 0.6822 - val_loss: 1.2533 - val_accuracy: 0.5768\n",
            "Epoch 42/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.8883 - accuracy: 0.6844 - val_loss: 1.3543 - val_accuracy: 0.5519\n",
            "Epoch 43/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.8747 - accuracy: 0.6904 - val_loss: 1.3228 - val_accuracy: 0.5781\n",
            "Epoch 44/120\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.8704 - accuracy: 0.6925 - val_loss: 1.2963 - val_accuracy: 0.5762\n",
            "Epoch 45/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.8589 - accuracy: 0.6938 - val_loss: 1.3397 - val_accuracy: 0.5787\n",
            "Epoch 46/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.8519 - accuracy: 0.6958 - val_loss: 1.3246 - val_accuracy: 0.5775\n",
            "Epoch 47/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.8431 - accuracy: 0.7011 - val_loss: 1.3455 - val_accuracy: 0.5765\n",
            "Epoch 48/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.8394 - accuracy: 0.7007 - val_loss: 1.3947 - val_accuracy: 0.5596\n",
            "Epoch 49/120\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.8203 - accuracy: 0.7084 - val_loss: 1.3170 - val_accuracy: 0.5744\n",
            "Epoch 50/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.8119 - accuracy: 0.7131 - val_loss: 1.3755 - val_accuracy: 0.5660\n",
            "Epoch 51/120\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.8122 - accuracy: 0.7099 - val_loss: 1.3481 - val_accuracy: 0.5737\n",
            "Epoch 52/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7955 - accuracy: 0.7150 - val_loss: 1.3956 - val_accuracy: 0.5713\n",
            "Epoch 53/120\n",
            "625/625 [==============================] - 41s 66ms/step - loss: 0.7794 - accuracy: 0.7232 - val_loss: 1.3611 - val_accuracy: 0.5735\n",
            "Epoch 54/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7791 - accuracy: 0.7214 - val_loss: 1.4124 - val_accuracy: 0.5493\n",
            "Epoch 55/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7746 - accuracy: 0.7236 - val_loss: 1.3736 - val_accuracy: 0.5647\n",
            "Epoch 56/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7618 - accuracy: 0.7279 - val_loss: 1.3975 - val_accuracy: 0.5692\n",
            "Epoch 57/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7514 - accuracy: 0.7306 - val_loss: 1.3936 - val_accuracy: 0.5775\n",
            "Epoch 58/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7493 - accuracy: 0.7303 - val_loss: 1.4454 - val_accuracy: 0.5599\n",
            "Epoch 59/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7409 - accuracy: 0.7339 - val_loss: 1.3614 - val_accuracy: 0.5741\n",
            "Epoch 60/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7325 - accuracy: 0.7369 - val_loss: 1.4340 - val_accuracy: 0.5629\n",
            "Epoch 61/120\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.7278 - accuracy: 0.7395 - val_loss: 1.3758 - val_accuracy: 0.5669\n",
            "Epoch 62/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7195 - accuracy: 0.7439 - val_loss: 1.4785 - val_accuracy: 0.5654\n",
            "Epoch 63/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7200 - accuracy: 0.7412 - val_loss: 1.3903 - val_accuracy: 0.5684\n",
            "Epoch 64/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.7004 - accuracy: 0.7484 - val_loss: 1.4044 - val_accuracy: 0.5753\n",
            "Epoch 65/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.6931 - accuracy: 0.7530 - val_loss: 1.3844 - val_accuracy: 0.5705\n",
            "Epoch 66/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.6969 - accuracy: 0.7505 - val_loss: 1.4397 - val_accuracy: 0.5635\n",
            "Epoch 67/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.6905 - accuracy: 0.7516 - val_loss: 1.4445 - val_accuracy: 0.5708\n",
            "Epoch 68/120\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.6717 - accuracy: 0.7587 - val_loss: 1.4672 - val_accuracy: 0.5763\n",
            "Epoch 69/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.6705 - accuracy: 0.7609 - val_loss: 1.5666 - val_accuracy: 0.5541\n",
            "Epoch 70/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.6692 - accuracy: 0.7599 - val_loss: 1.5379 - val_accuracy: 0.5691\n",
            "Epoch 71/120\n",
            "625/625 [==============================] - 39s 63ms/step - loss: 0.6589 - accuracy: 0.7626 - val_loss: 1.5474 - val_accuracy: 0.5602\n",
            "Epoch 72/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.6574 - accuracy: 0.7631 - val_loss: 1.4697 - val_accuracy: 0.5651\n",
            "Epoch 73/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.6607 - accuracy: 0.7623 - val_loss: 1.5098 - val_accuracy: 0.5782\n",
            "Epoch 74/120\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 0.6358 - accuracy: 0.7701 - val_loss: 1.5105 - val_accuracy: 0.5656\n",
            "Epoch 75/120\n",
            "469/625 [=====================>........] - ETA: 9s - loss: 0.6276 - accuracy: 0.7742"
          ]
        }
      ]
    }
  ]
}